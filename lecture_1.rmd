---
title: "mixed models: introduction"
author: "Ben Bolker"
date: "18 November 2025"
bibliography: "glmm.bib"
csl: reflist2.csl
nocite: |
  @banta_comprehensive_2010
output:
  ioslides_presentation:
    css: toc-style.css
    includes:
      in_header: TOC_generator.js.wrapper
    self_contained: true
header-includes:
- \usepackage{amsmath}
- \usepackage{amssymbol}
- \newcommand{\X}{\boldsymbol X}
- \newcommand{\Z}{\boldsymbol Z}
- \newcommand{\bbeta}{\boldsymbol \beta}
- \newcommand{\bb}{\boldsymbol b}
- \newcommand{\bu}{\boldsymbol u}
- \newcommand{\bLambda}{\boldsymbol \Lambda}
- \newcommand{\bEta}{\boldsymbol \eta}
- \newcommand{\btheta}{\boldsymbol \theta}
- \newcommand{\bzero}{\boldsymbol 0}
- \newcommand{\lik}{\mathcal L}

---

\newcommand{\bm}[1]{#1}

<style>
.refs {
   font-size: 16px;
}
h2 { 
 color: #3399ff;		
}
h3 { 
 color: #3399ff;		
}
.title-slide {
   background-color: #55bbff;
}
.smalltab {
    font-size: 10px;
}
</style>
<!--    content: url(https://i.creativecommons.org/l/by-sa/4.0/88x31.png)
>
<!-- Limit image width and height -->
<style type="text/css">
img {     
  max-height: 560px;     
  max-width: 800px; 
}
</style>


```{r knitr,include=FALSE, message = FALSE}
require("knitr")
knit_hooks$set(crop=hook_pdfcrop)
##opts_chunk$set(fig.width=5,fig.height=4,
##               out.width="0.6\\textwidth",
##               fig.align="center",echo=FALSE)
opts_chunk$set(echo=FALSE)
```

```{r pkgs,message=FALSE}
library(lattice)
library(plotrix) ## for axis.break
library(reshape2)
library(ggplot2)
library(RColorBrewer)
library(lme4)
library(tidyverse)
library(MASS)
library(nlme)
library(grid)
library(ggbeeswarm)
zmargin <- theme(panel.spacing=unit(0,"lines"))
library(scales) ## for 'scientific', 'trans_format'
theme_set(theme_bw())
```

```{r setup, include=FALSE}
set.seed(20251028)
OkIt <- unname(palette.colors(n = 8, palette = "Okabe-Ito"))[-1]
scale_colour_discrete <- function(...) {
  scale_colour_manual(..., values=OkIt)
}
scale_fill_discrete <- function(...) {
  scale_fill_manual(..., values=OkIt)
}
```

## Table of contents

<div id="toc"></div>

# Overview {.section}

## Mixed models 

* *tabular* data (row = observation, column = variable)
* *regression* models
   * continuous and categorical *predictor* variables
   * single (univariate) numeric *response* variable
* with one or more *grouping variables* ('blocks', 'clusters', ...)
* for prediction or inference
* typically for 'medium-sized' data (e.g. $10^6$ rows, $10^3$ clusters, 10-20 predictors)

## Mixed models (easy version)

* take a standard linear-type model (e.g. $y_i = a + b x_i + \epsilon_i$)
* ... but observations fall in *groups*
* breaks assumption of independence (*pseudoreplication*)
* add *between-group* (random) variation:
$$
y_{ij} = a + b x_{ij} + \alpha_i + \epsilon_{ij}
$$

## single group, categorical predictor<br>(= one-way ANOVA)

```{r oneanova, echo = FALSE, fig.width = 8}
ngrp <- 8
npergrp <- 10
dd <- expand.grid(g = factor(1:ngrp), obs = 1:npergrp) |>
  arrange(g)
dd$trt <- factor(rep(0:1, each=40), labels = c("control", "treatment"))
dd$y <- simulate( ~ 1 + trt + (1|g),
                 newdata = dd,
                 newparams = list(beta = c(1, 0.5),
                                  theta = 2,
                                  sigma = 0.2))[[1]]

## subsample to get lack of balance
samp <- sample(nrow(dd), size = round(0.5*nrow(dd)), replace = FALSE)
dds <- dd[samp,]
mdat <- data.frame(x0 = c(0.5, 4.5), x1 = c(4.5, 8.5), y = c(1, 1.5),
                   trt = factor(c("control", "treatment")))


ggplot(dds, aes(g, y)) +
  geom_boxplot(aes(fill = trt), alpha = 0.2) +
  ## geom_jitter(aes(colour = trt, shape = trt),
  ##              width = 0.2, height = 0) +
  geom_beeswarm(aes(colour = trt, shape = trt)) +
  labs(x = "group", y = "response",
       title = expression(list(beta == (list(1,0.5)),
                               sigma[alpha]==0.4,
                               sigma[r] == 0.2))) +
  geom_segment(aes(x = x0, xend = x1, y = y, yend = y,
                   colour = trt), data = mdat, lty = 2,
               alpha = 0.8)
```

## The mixed model universe

* more complex *fixed effects* components (multivariate regression, multiway ANOVA, ANCOVA, ...)
* multiple grouping variables (random effects *terms*)
* multiple effects varying across groups (*random slopes models* etc.)
* non-Normal *conditional distributions*
   * exponential dispersion family (à la GLMs): binomial/Poisson/etc.
   * weirder: Tweedie, $t$ distribution, Beta, ...
* nonlinearity: *link functions* (log, logit, etc.)
* structured covariances: autoregressive, compound symmetric, regression splines ...

##

```{r out.width='100%'}
knitr::include_graphics("pix/models-glmm.png")
```

# Examples {.section}

## Experimental: bloodworm cell survival

```{r glycera}
x <- read.csv("data/Live-Dead Tabulated Counts.csv")
## utility function for factoring/renaming variables before
##  lattice plot
rnfac <- function(dat,vars) {
  if (!all(vars %in% names(dat))) stop("unknown variable")
  for (v in vars) {
    dat[[v]] <- factor(dat[[v]])
    levels(dat[[v]]) <- paste(v,"=",round(as.numeric(levels(dat[[v]])),2),sep="")
  }
  dat
}
sc <- function(x) { (x-min(x))/diff(range(x))}
xsc <- x
predvars <- c("Osm","Cu","H2S","Anoxia")
for (i in predvars) {
  xsc[[i]] <- sc(xsc[[i]])
}
xsc$Osm <- xsc$Osm-0.5
## xsc$O2 <- 1-xsc$O2
## names(xsc)[names(xsc)=="O2"] <- "anox"
xr0 <- within(x,FractionAlive <- Alive/(Alive+Dead))
xr <- melt(subset(xr0,select=-c(Alive,Dead)),id.vars=1:5)

x4 <- dcast(xr,H2S+Anoxia+Cu+Osm~.,fun.aggregate=mean)
names(x4)[5] <- "all"
x5 <- rnfac(x4,c("Anoxia","Osm"))

## FIXME: replace with ColorBrewer colours?
cmgen.colors  <- function (n,h1=6/12,h2=10/12,maxs=0.5)  {
    if ((n <- as.integer(n[1])) > 0) {
        even.n <- n%%2 == 0
        k <- n%/%2
        l1 <- k + 1 - even.n
        l2 <- n - k + even.n
        c(if (l1 > 0) hsv(h = h1,
                          s = seq(maxs, ifelse(even.n, 0.5/k, 0), length.out = l1),
                          v = 1),
          if (l2 > 1) hsv(h = h2,
                          s = seq(0, maxs, length.out = l2)[-1],
                          v = 1))
    }
    else character(0)
}
rb.colors <- function(n) {
  cmgen.colors(n,h1=0,h2=0.7,maxs=1)
}
```
 

```{r glycplot1,out.width="\\textwidth",fig.width=8,fig.height=5}
orig <- trellis.par.get()
pad <- 0 ## 15 for regular layout
trellis.par.set(layout.widths=list(right.padding=pad,left.padding=pad),
                regions=list(col=rb.colors(100)),
##                regions=list(col=brewer.pal(11,"RdBu")),
## leave text alone for regular layout
                add.text=list(cex=0.8),axis.text=list(cex=0.5))
levels(x5$Anoxia) <- c("Normoxia","Anoxia")
## print(levelplot(`(all)`~factor(H2S)*factor(Cu)|Anoxia*Osm,
##          col.region=rb.colors(100),
##          data=x5,
##          xlab=expression(H[2]*S),
##          ylab="Copper"))
levelplot(all~factor(H2S)*factor(Cu)|Osm*Anoxia,
                col.region=rb.colors(100), ## brewer.pal(11,"RdBu"), ## rb.colors(100),
                data=x5,
                xlab=expression(H[2]*S),
          ylab="Copper",
          sub = "D. Julian, unpublished data")
trellis.par.set(theme=orig) ## restore settings
## FIXME: redo in ggplot2?  LOW PRIORITY
```

## *Arabidopsis*: fertilization & herbivory

```{r arabplot1,fig.width=7,fig.height=6}
panel.stripplot2 <-
function (x, y, jitter.data = FALSE, factor = 0.5, amount = NULL, 
    horizontal = TRUE, groups = NULL, ...) 
{
    if (!any(is.finite(x) & is.finite(y))) 
        return()
    panel.sizeplot(x = x, y = y, jitter.x = jitter.data && !horizontal, 
        jitter.y = jitter.data && horizontal, factor = factor, 
        amount = amount, groups = groups, horizontal = horizontal, 
        ...)
}
load("data/Banta.RData")
trellis.par.set(list(fontsize=list(text=20)))
stripplot(jltf ~ amd|nutrient, 
                data=within(dat.tf,jltf <-jitter(log(total.fruits+1),
                  amount=0.05)),
                strip=strip.custom(strip.names=c(TRUE,TRUE)),
                groups=gen, type=c('p','a'),
          ylab="Log(1+fruit set)",
          sub = "Banta et al. 2010")
##                main="panel: nutrient, color: genotype")
## trellis.par.set(theme=orig) ## restore settings
```

## Coral demography

```{r coral_demog,warning=FALSE}
L <- load("data/m.acr.jagsout.RData")
L2 <- load("data/m.acr.lme4out.RData")
L3 <- load("data/demog.mort.18apr.RData")
source("R/demog_mort_funs.R")
pp <- plotfun(j.red2,m.acr.nofr,drop.cols=c(4,8))
pp + labs(subtitle = "J.-S. White, unpublished")
```

## Sleep deprivation study

@belenkyPatterns2003

```{r sleepstudy}
data("sleepstudy", package = "lme4")
ggplot(sleepstudy, aes(Days, Reaction, group =Subject)) + geom_point() + geom_line() +
  labs(y = "Reaction time (ms)", x = "Experiment day") +
  scale_x_continuous(breaks = seq(0, 10, by = 2)) +
  geom_vline(xintercept =  2, lty = 2) +
  annotate(geom = "text", x=1, y=450, label = "adaptation/\ntraining") +
  annotate(geom = "text", x=3, y=450, label = "deprivation")
```

# Definitions and descriptions {.section}

## Simple mixed models<br>(scalar, intercept-only)

$$
\begin{split}
y_{ij} & = \beta_0 + \beta_1 x_{ij} + \epsilon_{0,ij} + \epsilon_{1,j} \\
& = (\beta_0 + \epsilon_{1,j}) + \beta_1 x_{ij} + \epsilon_{1,j} \\
\epsilon_{0,ij} & \sim \textrm{Normal}(0,\sigma_0^2) \\
\epsilon_{1,j} & \sim \textrm{Normal}(0,\sigma_1^2)
\end{split}
$$

- Could have multiple, nested levels of random effects  
(genotype within population within region ...), or *crossed* REs

## Random-slopes model

$$
\begin{split}
y_{ij} & = \beta_0 + \beta_1 x_{ij} + \epsilon_{0,ij} + \epsilon_{1,j} +
\epsilon_{2,j} x_{ij} \\
& = (\beta_0 + \epsilon_{1,j}) + (\beta_1 + \epsilon_{2,j}) x_{ij})  \\
\epsilon_{0,ij} & \sim \textrm{Normal}(0,\sigma_0^2) \\
\{\epsilon_{1,j}, \epsilon_{2,j}\} & \sim \textrm{MVN}(0,\Sigma)
\end{split}
$$

- variation in the *effect* of a treatment or covariate across groups
- group intercept, slope offsets are correlated

## Terminology

- **grouping variables** define sets of clusters (e.g. school, year, country ...)
- **varying effects** are predictors whose effects that vary across clusters (e.g. intercept, herbivory, time)
- a random effects **term** is the combination of a clustering variable and a set of varying effects
- a **conditional mode** is the predicted value of the *difference* of a cluster effect from the population mean (slope difference of a subject) (also "BLUPs")
- the **conditional distribution** is the probability distribution of the conditional modes (Gaussian for LMMs, or Poisson, Beta, Tweedie, ...)

## General definition

$$
\begin{split}
\underbrace{Y_i}_{\text{response}} & \sim \overbrace{\text{Distr}}^{\substack{\text{conditional} \\ \text{distribution}}}(\underbrace{g^{-1}(\eta_i)}_{\substack{\text{inverse} \\ \text{link} \\ \text{function}}},\underbrace{\phi}_{\substack{\text{scale} \\ \text{parameter}}}) \\
\underbrace{\boldsymbol \eta}_{\substack{\text{linear} \\ \text{predictor}}} & 
 = 
\underbrace{\boldsymbol X \boldsymbol \beta}_{\substack{\text{fixed} \\ \text{effects}}} + 
\underbrace{\boldsymbol Z \boldsymbol b}_{\substack{\text{random} \\ \text{effects}}}
\\
\underbrace{\boldsymbol b}_{\substack{\text{conditional} \\ \text{modes}}}  & 
\sim \text{MVN}(\boldsymbol 0, \underbrace{\Sigma(\boldsymbol \theta)}_{\substack{\text{variance-} \\ \text{covariance} \\ \text{matrix}}})
\end{split}
$$

## What are random effects?

A method for …

- accounting for among-individual variation, within-cluster correlation
- compromising between\
    *complete pooling* (no among-cluster variance)\
     and *fixed effects* (large among-cluster variance)
-   handling levels selected at random from a larger population
- sharing information among clusters (*shrinkage estimation*)
- estimating among-cluster variability
- allowing predictions for unobserved clusters
- modeling **exchangeable** groups

## Random-effect myths

- clusters must always be sampled at random
- a complete sample cannot be treated as a random effect
- random effects are always a *nuisance variable*
- nothing can be said about the predictions of a random effect
- you should always use a random effect no matter how few clusters you have

## Reasons for random effects (inferential/philosophical)

- **don't** want to
     - test hypotheses about differences between responses at particular levels of
the grouping variable;
- **do** want to
     - quantify variation among groups
     - make predictions about unobserved groups
- have levels that are randomly sampled from/representative of a larger population (*exchangeable*)


## Reasons for random effects (practical)

- want to combine information across groups
- have variation in information per level (number of samples or noise level)
- have a categorical predictor that is a nuisance variable (i.e., not of direct interest, but needs to be controlled for)
- have more than 5-6 groups that could be considered exchangeable

See also @Crawley2002; @gelman_analysis_2005

## Avoiding mixed models

* average: for *nested* (balanced) LMMs [@murtaugh_simplicity_2007] 
* use fixed effects (or *two-stage models*) instead of random effects when there are
     * many observations per cluster (shrinkage unimportant)
     * few clusters (little advantage; bad variance estimates)

# Model setup {.section}

## Formulas

- random effects specified with `|` ("pipe"/"bar")  
as `(1+a|g1) + (1+b|g2) + ...`
- right-hand side (`g1`, `g2`) is the *grouping variable* (always treated as categorical, usually a factor)
- left-hand side describes the *varying terms* (`1` [intercept], `a`, `b`)
- `+` separates independent terms
- formulas: empower but conceal details [@mcelreath_statistical_2015]

## Formula definitions {.smalltab}

```{r ftab,echo=FALSE,results="asis"}
ftab <- matrix(c("β_0 + β_{1}X_{i} + e_{si}",
                 "n/a (Not a mixed-effects model)",
                 "(β_0 + b_{S,0s}) + β_{1}X_i + e_{si}",
                 "∼ X + (1∣Subject)",
                 "(β_0 + b_{S,0s}) +  (β_{1} + b_{S,1s}) X_i + e_{si}",
                 "~ X + (1 + X∣Subject)",
                 "(β_0 + b_{S,0s} + b_{I,0i}) + (β_{1} + b_{S,1s}) X_i + e_{si}",
                 "∼ X + (1 + X∣Subject) + (1∣Item)",
                 "As above, but $S_{0s}$, $S_{1s}$ independent",
                 "∼ X + (1||Subject) + (1∣Item)", 
                 "(β_0 + b_{S,0s} + b_{I,0i}) + β_{1}X_i + e_{si}",
                 "∼ X + (1∣Subject) + (1∣Item)", 
                 "(β_0 + b_{I,0i}) +  (β_{1} + b_{S,1s})X_i + e_{si}",
                 "∼ X + (0 + X∣Subject) + (1∣Item)"),
               byrow=TRUE,ncol=2,
               dimnames=list(NULL,c("equation","formula")))
ftab <- data.frame(ftab,stringsAsFactors=FALSE)
ff <- !grepl("As above",ftab$equation)
ftab$equation[ff] <- sprintf("$%s$",ftab$equation[ff])
ff <- !grepl("n/a",ftab$formula)
ftab$formula[ff] <- sprintf("`%s`",ftab$formula[ff])
pander::pander(ftab,justify="left")
```

Modified from: http://stats.stackexchange.com/questions/13166/rs-lmer-cheat-sheet?lq=1 (Livius). Subscripts $\{S,I\}$ refer to Subject vs Item effects. Lower-case $\{s,i\}$ indicate particular subjects/items. $\{0,1\}$ refer to intercept vs slope effects.

## Nesting vs crossing

Nested: sub-unit IDs only measured within a single larger unit.
e.g.: Class1 in School1 independent of Class1 in School2

![](pix/CV_nested.png)

Crossed: sub-unit IDs can be measured in multiple larger units.
e.g. 

![](pix/CV_crossed.png)

Unique coding: removes ambiguity

![](pix/CV_unique.png)

Robert Long, [Cross Validated](https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified)

## Formulas, interactions, nesting etc.

- Nested: `(1|f/g)` $\equiv$ `(1|f) + (1|f:g)`. Subplots vary within plots, no commonality across plots
- Crossed: `(1|f) + (1|g)`. Years vary; plots vary independently
- Crossed+: `(1|f*g)` $\equiv$ `(1|f) + (1|g) + (1|f:g)`. Years vary, plots vary independently, plots vary within years (need >1 observation per plot/year combination).

**Don't need explicit nesting** if sub-groups are uniquely labeled (i.e. `A1`, `A2`, ..., `B1`, `B2`, ...)

## example covariance matrices

* 10 groups, 5 obs/group, intercept RE

```{r plotcov1, message = FALSE}
source("funs.R")
fit <- simfun(c(10,1), c(1,1),  5,
       y ~ 1 + (1|g),
       list(beta = 1, theta = 1, sigma = 1))
plotfun(fit)
```

## example covariance matrices

* 10 groups, 5 obs/group, 3 effects/group

```{r plotcov2, message=FALSE}
fit2 <- simfun(c(10, 1), c(3,1), 3,
       y ~ 1 + (v|g),
       list(beta = 1, theta = c(2,1,1,2,1,0.1), sigma = 1))
plotfun(fit2)
```

##  example covariance matrices

* 5 groups, 2 effects (v1) × 5 groups, 1 effect (v1)

```{r plotcov3, message=FALSE}
fit3 <- simfun(c(5, 5), c(2, 1), 3,
       y ~ 1 + (v|g) + (1|g2),
       list(beta = 1, theta = c(1,1,1,1), sigma = 1))
plotfun(fit3)
```

##  example covariance matrices

Real example (fire/diversity; blocks are geographic regions)

```{r ecoreg_cov, message=FALSE}
mod_list <- readRDS("outputs/mod_list.rds")
plotfun(mod_list[["m_full"]])
```

## Factors varying across groups

Can generate large variance-covariance matrices. For a four-level factor, we have $\beta_0$ (intercept), $\beta_1$ (level 2 - level 1), $\beta_2$ (level 3 - level 1), $\beta_3$ (level 4 - level 1).

$$
\Sigma = 
\left[
\begin{array}{cccc}
\sigma^2_{\{b|1\}}  & . & . & . \\
\sigma_{\{b|1\},\{b|a_{21}\}} &
\sigma^2_{\{b|a_{21}\}} & . & .  \\
\sigma_{\{b|1\},     \{b|a_{31}\}} &
\sigma_{\{b|a_{21}\},\{b|a_{31}\}} &
\sigma^2_{\{b|a_{31}\}} & . \\
\sigma_{\{b|1\}     ,\{b|a_{41}\}} &
\sigma_{\{b|a_{21}\},\{b|a_{41}\}} &
\sigma_{\{b|a_{31}\},\{b|a_{41}\}} &
\sigma^2_{\{b|a_{41}\}} 
\end{array}
\right]
$$

## What is the maximal model?

- Which effects vary *within* which groups?
- If effects don't vary within groups, then we *can't* estimate among-group variation in the effect
     - e.g. in typical clinical trials each patient gets only one treatment (placebo or drug)
     - convenient
     - maybe less powerful (among-group variation is lumped into residual variation)
	 - can't evaluate variation in effects

## Maximal model is often impractical

- for a RE where $n$ effects vary across clusters we need to estimate $p = n(n+1)/2$ covariance parameters
- e.g. bloodworm example: 5×4×4×2 factorial design (160 combinations), all measured in each of 10 individuals. 
    - Treating covariates as numeric, allow all interactions:  
	16 effects → $p=136$
    - Categorical predictors, no interactions:  
	12 effects → $p=78$
    - Numeric predictors, no interactions: 4 effects → $p=10$
- **BUT** ignoring within-cluster effects is also dangerous [@schielzeth_conclusions_2009; @heisigWhy2019a; @oberauerImportance2022] (!)


# Estimation {.section}

## Maximum likelihood estimation

-   Best fit is a compromise between
  * consistency of data with fixed effects + conditional modes
  * consistency of random effect with RE distribution
- Goodness-of-fit *integrates* over the RE distribution

$$
\lik(x|\beta,\theta) = \iint \lik(x|\beta,\bb) \cdot \lik(\bb|\Sigma(\theta)) \, d \bb
$$

## Restricted maximum likelihood (REML)

- factor out fixed effects when estimating variances
- analogous to estimating $s^2 = \frac{\textrm{SSQ}}{n-1}$ rather than $\frac{\textrm{SSQ}}{n}$
- typically better variance estimates (unbiased in simple cases)
- defaults differ across packages
- **never** compare models with differing fixed effects fitted by REML ![](pix/skullcross_tiny.png)

## Shrinkage

```{r anova-shrink, message = FALSE, warning=FALSE}
anova_fit <- lmer(y ~ 1 + (1|g), data = dds)
pframe <- unique(subset(dds, select = c("g", "trt")))
pframe$y <- predict(anova_fit, newdata = pframe)
sframe <- subset(pframe, g=="4")
## duplicate
sframe <- sframe[c(1,1),]
sframe$y[2] <- mean(subset(dds, g=="4")$y)
sframe$lab <- c("conditional mode", "group mean")
ggplot(dds, aes(g, y, colour = trt)) +
  ## geom_jitter(aes(colour = trt, shape = trt),
  ##              width = 0.2, height = 0) +
  geom_beeswarm(aes(shape = trt), alpha = 0.4) +
  stat_summary(fun = mean, size = 0.5, pch = 15) +
  geom_point(data = pframe, pch = 16, size = 2) +
  labs(x = "group", y = "response",
       title = expression(list(beta == (list(1,0.5)),
                               sigma[alpha]==0.4,
                               sigma[r] == 0.2))) +
  geom_segment(aes(x = x0, xend = x1, y = y, yend = y,
                   colour = trt), data = mdat, lty = 2,
               alpha = 0.8) +
  geom_label(aes(label = lab), data = sframe, hjust = -0.1) +
  theme(legend.position = "none")
```

## *Arabidopsis* shrinkage

```{r arabshrink,fig.height=6,fig.width=8}
z<- subset(dat.tf,amd=="clipped" & nutrient=="1")
m1 <- glm(total.fruits~gen-1,data=z,family="poisson")
m2 <- glmer(total.fruits~1+(1|gen),data=z,family="poisson")
tt <- table(z$gen)
rr <- unlist(ranef(m2)$gen)[order(coef(m1))]+fixef(m2)
m1s <- sort(coef(m1))
m1s[1:2] <- rep(-5,2)
gsd <- attr(VarCorr(m2)$gen,"stddev")
gm <- fixef(m2)
nseq <- seq(-3,6,length.out=50)
sizefun <- function(x,smin=0.5,smax=3,pow=2) {
    smin+(smax-smin)*((x-min(x))/diff(range(x)))^pow
}
nv <- dnorm(nseq,mean=gm,sd=gsd)
##
op <- par(las=1,cex=1.5,bty="l")
plot(exp(m1s), xlab="Genotype", ylab="Mean fruit set",
     axes=FALSE,xlim=c(-0.5,25), log="y", yaxs="i", xpd=NA,
     pch=16, cex=0.5,
     ylim = c(exp(-5), 50))
axis(side=1)
tkvec <- c(exp(-5),0.1,0.5, 1,5,10,50)
tklabs <- tkvec; tklabs[1] <- 0
axis(side=2, at = tkvec, labels = tklabs, cex = 0.8)
##     ylim=c(-3,5))
polygon(c(rep(0,50),nv*10),exp(c(rev(nseq),nseq)),col="gray",xpd=NA)
n <- tt[order(coef(m1))]
points(exp(rr),pch=16,col=adjustcolor("red",alpha=0.5),
       cex=sizefun(n),xpd=NA)
## text(seq_along(rr),rr,n,pos=3,xpd=NA,cex=0.6)
box()
axis.break(axis=2,breakpos=exp(-4))
legend("bottomright",
       c("group mean","shrinkage est."),
       pch=16,pt.cex=c(1,2),
       col=c("black",adjustcolor("red",alpha=0.5)),
       bty="n")
par(op)
```

## Shrinkage in the sleep-study model

```{r shrink_ss, echo = FALSE, fig.width = 10, fig.height = 5}
fm1 <- lmer(Reaction ~ Days + (1+Days|Subject), sleepstudy)
sleepstudy$predy <- predict(fm1)
gg_spaghetti <- ggplot(sleepstudy, aes(Days, Reaction, colour =Subject)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", se=FALSE, lty=2, formula = y~x) +
  colorspace::scale_colour_discrete_qualitative() +
  geom_line(aes(y = predy), lty = 1) +
  labs(y = "Reaction time (ms)", x = "Experiment day") +
  scale_x_continuous(breaks = seq(0, 10, by = 2))
cfun <- function(x) { as.data.frame(x) |>
                        setNames(c("intercept", "slope")) |>
                        tibble::rownames_to_column("Subject") |>
                        as_tibble()
}
dd1 <- cfun(coef(fm1)$Subject)
dd2 <- cfun(coef(lmList(Reaction ~ Days | Subject, sleepstudy)))
dd12 <- dplyr::bind_rows(list(fixed=dd2, random = dd1), .id = "method")
dd3 <- dplyr::full_join(dd1, dd2, by = "Subject")
pm <- colMeans(as.matrix(dd2[,-1]))
gg_shrink <- ggplot(dd12, aes(intercept, slope)) + geom_point(aes(colour = method), size = 5) +
  geom_segment(data = dd3, aes(x = intercept.y, xend = intercept.x,
                               y = slope.y, yend = slope.x), arrow = grid::arrow(length = grid::unit(0.03, "npc"))) +
  annotate(geom = "point", x = pm[["intercept"]], y = pm[["slope"]], size = 5, stroke = 3, pch = 3)
cowplot::plot_grid(gg_spaghetti, gg_shrink)
```

```{r sleepstudy_shrinkage, echo=FALSE, eval = FALSE}
# From Christophe Lalanne, see [here](https://stats.stackexchange.com/questions/51186/what-would-be-an-illustrative-picture-for-linear-mixed-models):

library(lme4)
data(sleepstudy)

## Fit individual regression lines for each subject
dfrm <- coef(lmList(Reaction ~ Days | Subject, sleepstudy))

## Estimate parameters of a random intercept and random intercept and slope model
m1 <- lmer(Reaction ~ Days + (1 | Subject), data=sleepstudy)
m2 <- lmer(Reaction ~ Days + (Days | Subject), data=sleepstudy)

## Put all estimates (intercept + slope for each model) into the same data.frame
dfrm <- cbind.data.frame(dfrm,
                         as.data.frame(coef(m1)[["Subject"]]),
                         as.data.frame(coef(m2)[["Subject"]]))

## Kernel density estimates for the distribution of individual intercepts
intcpt.dens <- list()
idx <- seq(1, ncol(dfrm), by=2)
for (i in seq_along(idx))
  intcpt.dens[[i]] <- density(as.numeric(dfrm[,idx[i]]), adj=1.4)
len <- length(intcpt.dens[[1]]$x)

## Show all
cols <- c("grey30", "#D95F02", "#669999")
xyplot(Reaction ~ Days, data=sleepstudy,
       xlim=c(0, 8), ylim=c(150, 450), ylab="Fitted reaction time",
       scales=list(x=list(at=seq(0, 8, by=1))),
       key=list(corner=c(0,1), text=list(c("within-group",
                                 "random intercept",
                                 "random intercept and slope"),
                                 col=cols, cex=0.8)),
       panel=function(...) {
         apply(dfrm[,1:2], 1, panel.abline, col=cols[1], alpha=.5, lwd=1.2)
         apply(dfrm[,3:4], 1, panel.abline, col=cols[2], alpha=.5, lwd=1.2)
         for (i in seq_along(idx))
         panel.lines(x=c(intcpt.dens[[i]]$y*100, rep(0, len)),
                     y=c(intcpt.dens[[i]]$x, rev(intcpt.dens[[i]]$x)), col=cols[i], lwd=1.8)
})
```

# Methods

## Estimation methods

Integrating the likelihood is hard for GLMMs

- deterministic approximations:
    - penalized quasi-likelihood [@breslow_whither_2004], Laplace, Gauss-Hermite quadrature, … [@biswas2015; @bilodeauStochastic2024]
	- best methods needed for small clusters
	- available methods depend on problem structure
    - accuracy (GHQ) vs. flexibility and speed (Laplace, PQL)
- stochastic approximations (Monte Carlo): mostly Bayesian, some frequentist
    - @booth_maximizing_1999; @gelman_data_2006; @sung_monte_2007; @ponciano_hierarchical_2009; @mcelreath_statistical_2015
    - much slower, but flexible and accurate

## Estimation: *Arabidopsis*

```{r arab_coefplot}
tt <- readRDS("outputs/banta_fits1.rds")
tt |> filter(is.na(effect) | effect == "fixed") |>
  ggplot(aes(estimate, term, colour = method)) +
  geom_pointrange(aes(xmin = conf.low, xmax = conf.high),
                  position = position_dodge(width = 0.25, reverse = TRUE)) +
  geom_vline(xintercept = 0, lty = 2)
```

# Inference/post-fitting {.section}

## Diagnostics

* make sure model is working OK (**singular fits** etc.)
* check model assumptions
    * generalizations of linear/GLM diagnostics: residuals vs fitted, scale-location, etc.
	* conditional modes should be Normally distributed
	* simulation-based checking (`DHARMa`)

## Parameter/model interpretation

* fixed effects: same as linear models (population level trends/effects)
* conditional modes/group-level effects
	* deviations from population-level effects
    * can get *conditional standard deviations*, but can't test significance!
* interpreting random effects
    * standard deviations (on same scale as corresponding fixed effects)
	* variances (for population geneticists)

<style>
slides > slide { overflow: scroll; }
slides > slide:not(.nobackground):after {
  content: '';
}
</style>

## references  {.refs}
